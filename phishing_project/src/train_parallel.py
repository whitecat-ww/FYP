import pandas as pd
import numpy as np
import joblib
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from feature_extractor import extract_features, features_to_vector, FEATURE_ORDER
from tqdm import tqdm
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½® ---
# çº¿ç¨‹æ•°é‡ï¼šæ ¹æ®ä½ çš„ç½‘é€Ÿè°ƒæ•´ï¼Œé€šå¸¸ 20-50 æ¯”è¾ƒåˆé€‚
# å¤ªé«˜å¯èƒ½ä¼šè¢«ç½‘ç«™å° IPï¼Œå¤ªä½é€Ÿåº¦æä¸ä¸Šæ¥
MAX_WORKERS = 50 

# å®šä¹‰è·¯å¾„
BASE_DIR = os.path.dirname(__file__)
NEW_DATA_PATH = os.path.join(BASE_DIR, "../data/phishing_dataset.csv")
MODEL_OUT = os.path.join(BASE_DIR, "../models/phishing_rf.pkl")

def process_single_url(data):
    """
    å•ä¸ª URL çš„å¤„ç†å‡½æ•°ï¼Œç”¨äºå¤šçº¿ç¨‹è°ƒç”¨
    """
    url, label = data
    try:
        # è¿™é‡Œè°ƒç”¨ä½ åŸæ¥çš„æå–é€»è¾‘ï¼ŒåŒ…å«ç½‘ç»œè¯·æ±‚
        feats = extract_features(url)
        vec = features_to_vector(feats)
        return vec, label
    except Exception:
        # å¦‚æœæŸä¸ª URL æå–å¤±è´¥ï¼ˆæ¯”å¦‚ç½‘ç«™æŒ‚äº†ï¼‰ï¼Œè¿”å› None
        return None

def load_data_parallel(path):
    print(f"Loading raw data from {path}...")
    if not os.path.exists(path):
        raise FileNotFoundError(f"{path} not found.")
    
    df = pd.read_csv(path)
    
    # ä¸ºäº†æ¼”ç¤ºé€Ÿåº¦ï¼Œå¦‚æœä½ åªæƒ³æµ‹è¯•ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šï¼Œåªå–å‰ 1000 æ¡
    # df = df.head(1000) 
    
    # æŸ¥æ‰¾æ ‡ç­¾åˆ—
    target_col = 'status' if 'status' in df.columns else 'label'
    if 'url' not in df.columns or not target_col:
        raise ValueError("CSV must have 'url' and 'label' columns")

    urls = df['url'].values
    labels = df[target_col].values
    
    # å‡†å¤‡æ•°æ®å¯¹
    data_pairs = list(zip(urls, labels))
    total = len(data_pairs)
    
    print(f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹æå– (çº¿ç¨‹æ•°: {MAX_WORKERS})...")
    print("è¿™ä¼šæ¯”å•çº¿ç¨‹å¿«å‡ åå€ï¼Œä½†ä»éœ€ä¸€ç‚¹æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    processed_rows = []
    processed_labels = []
    
    start_time = time.time()
    
    # --- æ ¸å¿ƒï¼šå¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œ ---
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {executor.submit(process_single_url, pair): pair for pair in data_pairs}
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        for future in tqdm(as_completed(futures), total=total, unit="url"):
            result = future.result()
            if result is not None:
                vec, label = result
                processed_rows.append(vec)
                processed_labels.append(label)
                
    end_time = time.time()
    duration = end_time - start_time
    print(f"\nâœ… ç‰¹å¾æå–å®Œæˆï¼")
    print(f"è€—æ—¶: {duration:.2f} ç§’")
    print(f"å¹³å‡é€Ÿåº¦: {len(processed_rows) / duration:.2f} URL/s")
    
    # è½¬æ¢ä¸º DataFrame
    X = pd.DataFrame(processed_rows, columns=FEATURE_ORDER)
    
    # å¤„ç†æ ‡ç­¾
    y_raw = pd.Series(processed_labels)
    if y_raw.dtype == object:
        y = y_raw.apply(lambda x: 1 if str(x).lower().strip() == 'phishing' else 0)
    else:
        y = y_raw.astype(int)
        
    return X, y

def main():
    # 1. å¹¶è¡ŒåŠ è½½æ•°æ®
    try:
        X, y = load_data_parallel(NEW_DATA_PATH)
    except Exception as e:
        print(f"Error: {e}")
        return

    if len(X) == 0:
        print("æ²¡æœ‰æå–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œç¨‹åºç»“æŸã€‚")
        return

    # 2. åˆ†å‰²æ•°æ®
    print(f"Splitting {len(X)} samples...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

    # 3. GPU è®­ç»ƒ (è¿™æ­¥æ˜¯æ¯«ç§’çº§çš„)
    print("ğŸš€ Training XGBoost with RTX 4070 Super...")
    
    clf = XGBClassifier(
        n_estimators=500,
        max_depth=10,
        learning_rate=0.05,
        n_jobs=-1,
        device="cuda",      # ä½¿ç”¨ GPU
        tree_method="hist"  # æé€Ÿæ¨¡å¼
    )
    
    clf.fit(X_train, y_train)
    print("âœ… Model trained!")

    # 4. è¯„ä¼°
    preds = clf.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, preds))
    print(classification_report(y_test, preds))

    # 5. ä¿å­˜
    os.makedirs(os.path.dirname(MODEL_OUT), exist_ok=True)
    joblib.dump({'model': clf, 'feature_order': FEATURE_ORDER}, MODEL_OUT)
    print(f"Model saved to {MODEL_OUT}")

if __name__ == "__main__":
    main()